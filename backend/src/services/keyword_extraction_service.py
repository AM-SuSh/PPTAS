"""å…³é”®è¯æå–æœåŠ¡"""

import re
from typing import List, Dict, Any, Optional
from langchain.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
import json

from ..agents.base import LLMConfig


class KeywordExtractionService:
    """ä»PPTå†…å®¹ä¸­æå–æœ‰æ„ä¹‰çš„ä¸­æ–‡åè¯çŸ­è¯­"""
    
    def __init__(self, llm_config: LLMConfig):
        self.llm = llm_config.create_llm(temperature=0.5)
        self.llm_config = llm_config
    
    def extract_keywords(self, content: str, title: str = "", num_keywords: int = 5, raw_points: List[dict] = None) -> List[str]:
        """ä»å†…å®¹ä¸­æå–å…³é”®è¯
        
        Args:
            content: é¡µé¢å†…å®¹
            title: é¡µé¢æ ‡é¢˜
            num_keywords: è¦æå–çš„å…³é”®è¯æ•°é‡
            raw_points: åŸå§‹æ•°æ®ç‚¹åˆ—è¡¨
        
        Returns:
            å…³é”®è¯åˆ—è¡¨
        """
        # å¦‚æœ content ä¸ºç©ºï¼Œå°è¯•ä» raw_points æ„å»ºå†…å®¹
        if not content or not content.strip():
            if raw_points and len(raw_points) > 0:
                # ä»raw_pointsä¸­æå–æ‰€æœ‰æ–‡æœ¬
                points_text = []
                for point in raw_points:
                    if isinstance(point, dict):
                        if point.get('type') == 'text' and point.get('text'):
                            points_text.append(point.get('text', ''))
                        elif point.get('type') == 'table' and point.get('data'):
                            table_rows = point.get('data', [])
                            for row in table_rows:
                                if isinstance(row, list):
                                    points_text.extend([str(cell) for cell in row if cell])
                    else:
                        points_text.append(str(point))
                
                if points_text:
                    content = "é¡µé¢å†…å®¹ï¼š" + " | ".join(points_text[:10]) 
                    print(f"   ğŸ“ ä»raw_pointsæ„å»ºå†…å®¹: {content[:100]}")
            
            # å¦‚æœè¿˜æ˜¯æ²¡æœ‰contentï¼Œç”¨æ ‡é¢˜
            if not content or not content.strip():
                if title and title.strip() and title != "1":  
                    content = f"é¡µé¢æ ‡é¢˜: {title}"
                else:
                    return []
        
        max_content_length = 2000
        content = content[:max_content_length]
        
        template = """ä½ æ˜¯ä¸€ä¸ªå†…å®¹å…³é”®è¯æå–ä¸“å®¶ã€‚ä»PPTé¡µé¢çš„å®é™…å†…å®¹ä¸­æå–æœ€é‡è¦çš„æ¦‚å¿µå’Œä¿¡æ¯ã€‚

é¡µé¢æ ‡é¢˜: {title}

é¡µé¢å†…å®¹:
{content}

æå–ä»»åŠ¡ï¼š
1. é˜…è¯»é¡µé¢çš„å®é™…å†…å®¹ï¼ˆé€šå¸¸æ˜¯ç»“æ„åŒ–çš„ä¿¡æ¯ç‚¹ï¼‰
2. æå–{num_keywords}ä¸ªæœ€é‡è¦çš„**æœ‰å®é™…æ„ä¹‰çš„åè¯çŸ­è¯­**
3. æå–æŒ‡å¯¼ï¼š
   - â­ ç›´æ¥ä»å†…å®¹ä¸­æå–**å…·ä½“çš„æ¦‚å¿µã€ä¸»é¢˜ã€äººåã€æŠ€æœ¯åç§°ã€äº§å“å**ç­‰
   - â­ ä¾‹å¦‚ï¼šå¦‚æœé¡µé¢è®²"æ–°å…´æŠ€æœ¯ä¸æ•°æ®å®‰å…¨"ï¼Œæå–"æ–°å…´æŠ€æœ¯"ã€"æ•°æ®å®‰å…¨"
   - â­ ä¾‹å¦‚ï¼šå¦‚æœé¡µé¢æœ‰è®²å¸ˆåå­—ï¼Œç›´æ¥æå–è®²å¸ˆåå­—
   - â­ ä¾‹å¦‚ï¼šå¦‚æœæœ‰åˆ—è¡¨ï¼Œæå–**åˆ—è¡¨é¡¹çš„æ ¸å¿ƒæ¦‚å¿µ**ï¼Œè€Œä¸æ˜¯"åˆ—è¡¨"æœ¬èº«
   - â­ æå–çš„åº”è¯¥æ˜¯ç”¨æˆ·**çœŸæ­£å…³å¿ƒçš„ä¸»é¢˜å’Œå†…å®¹**
   - â­ é¿å…æå–é‚£äº›**æ ¼å¼æˆ–æ ‡ç­¾**ï¼ˆå¦‚"è®²æ¬¡"ã€"é‚®ç®±"ã€"æ ‡é¢˜"ç­‰ä¿®é¥°è¯ï¼‰
4. æ¯ä¸ªå…³é”®è¯é•¿åº¦ä¸å°‘äº2ä¸ªå­—ç¬¦
5. é¿å…çº¯è‹±æ–‡ã€çº¯æ•°å­—æˆ–çº¯ç¬¦å·
6. å…³é”®è¯åº”è¯¥æ¥è‡ªé¡µé¢å†…å®¹ï¼Œä¸åº”è¯¥æ˜¯å½¢å¼æè¿°

è¿”å›æ ¼å¼ï¼šJSONæ•°ç»„ï¼Œä¾‹å¦‚:
["æ–°å…´æŠ€æœ¯", "æ•°æ®å®‰å…¨", "é«˜å·¾æ·"]

ä¸¥æ ¼è¦æ±‚: åªè¿”å›JSONæ•°ç»„ã€‚æå–çš„æ¯ä¸ªå…³é”®è¯éƒ½æ˜¯é¡µé¢è®¨è®ºçš„**å®é™…ä¸»é¢˜å’Œå†…å®¹**ã€‚"""
        
        prompt = ChatPromptTemplate.from_template(template)
        chain = prompt | self.llm
        
        try:
            response = chain.invoke({
                "title": title or "æœªçŸ¥",
                "content": content,
                "num_keywords": num_keywords
            })
            
            response_text = response.content.strip()
            print(f"ğŸ“ LLMåŸå§‹å“åº”: {response_text[:100]}")
            
            # æå–JSONæ•°ç»„
            keywords = self._parse_keywords_response(response_text, num_keywords)
            
            print(f"ğŸ” è§£æåå…³é”®è¯: {keywords}")
            
            # éªŒè¯å’Œæ¸…ç†å…³é”®è¯
            validated_keywords = self._validate_keywords(keywords)
            
            print(f"âœ… éªŒè¯åå…³é”®è¯: {validated_keywords}")
            
            # å¦‚æœéªŒè¯åæ²¡æœ‰å…³é”®è¯ï¼Œè¿”å›åŸå§‹è§£æçš„å…³é”®è¯ï¼ˆå®½æ¾æ¨¡å¼ï¼‰
            if not validated_keywords and keywords:
                print(f"âš ï¸  éªŒè¯è¿‡äºä¸¥æ ¼ï¼Œä½¿ç”¨åŸå§‹å…³é”®è¯")
                validated_keywords = keywords[:num_keywords]
            
            # ç¡®ä¿è¿”å›æŒ‡å®šæ•°é‡çš„å…³é”®è¯
            return validated_keywords[:num_keywords]
            
        except Exception as e:
            print(f"âŒ å…³é”®è¯æå–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def _parse_keywords_response(self, response_text: str, num_keywords: int) -> List[str]:
        """ä»LLMå“åº”ä¸­è§£æå…³é”®è¯"""
        try:
            # å°è¯•ç›´æ¥è§£æJSON
            if "[" in response_text and "]" in response_text:
                # æå–JSONæ•°ç»„éƒ¨åˆ†
                start = response_text.find("[")
                end = response_text.rfind("]") + 1
                json_str = response_text[start:end]
                print(f"  ğŸ“¦ æå–JSON: {json_str}")
                keywords = json.loads(json_str)
                
                if isinstance(keywords, list):
                    result = [str(k).strip() for k in keywords if k]
                    print(f"  âœ… JSONè§£ææˆåŠŸ: {len(result)}ä¸ªå…³é”®è¯")
                    return result
        except json.JSONDecodeError as e:
            print(f"  âš ï¸ JSONè§£æå¤±è´¥: {e}")
        except Exception as e:
            print(f"  âš ï¸ JSONæå–å¼‚å¸¸: {e}")
        
        # å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•è¡Œåˆ†å‰²
        print(f"  ğŸ”„ å°è¯•è¡Œåˆ†å‰²è§£æ...")
        lines = [line.strip() for line in response_text.split('\n') if line.strip()]
        keywords = []
        for line in lines:
            # ç§»é™¤åˆ—è¡¨æ ‡è®° (- æˆ–æ•°å­—.)
            line = re.sub(r'^[-\d.]\s*', '', line).strip()
            # ç§»é™¤å¼•å·
            line = line.strip('"\'')
            # ç§»é™¤æ‹¬å·å†…çš„å†…å®¹
            line = re.sub(r'\([^)]*\)', '', line).strip()
            if line and len(line) >= 2:
                keywords.append(line)
        
        print(f"  âœ… è¡Œåˆ†å‰²è§£ææˆåŠŸ: {len(keywords)}ä¸ªå…³é”®è¯")
        return keywords
    
    def _validate_keywords(self, keywords: List[str]) -> List[str]:
        """éªŒè¯å…³é”®è¯ï¼Œç¡®ä¿ç¬¦åˆè¦æ±‚"""
        validated = []
        
        # æ ¼å¼æ ‡ç­¾å’Œä¿®é¥°è¯é»‘åå• - åªè¿‡æ»¤é‚£äº›æ ¼å¼åŒ–æ ‡è®°ï¼Œä¸è¿‡æ»¤å®é™…å†…å®¹
        form_labels = {
            'è®²æ¬¡', 'è®²', 'ç¬¬', 'æ ‡é¢˜', 'è¯´æ˜', 'å¤‡æ³¨', 'é‚®ç®±', 'ç½‘å€', 'ç”µè¯',
            'ä½œè€…', 'å‡ºç‰ˆ', 'æ¥æº', 'é“¾æ¥', 'å‚è€ƒ', 'é™„æ³¨', 'è„šæ³¨', 'æ³¨é‡Š',
            'é™„ä»¶', 'å›¾ç‰‡', 'å›¾è¡¨', 'è§†é¢‘', 'éŸ³é¢‘', 'èµ„æº'
        }
        
        for keyword in keywords:
            if not keyword:
                continue
            
            keyword = keyword.strip()
            
            # æ£€æŸ¥é•¿åº¦ï¼ˆè‡³å°‘2ä¸ªå­—ç¬¦ï¼‰
            if len(keyword) < 2:
                continue
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ ¼å¼æ ‡ç­¾è¯æ±‡ï¼ˆä¸¥æ ¼é™å®šï¼‰
            if keyword in form_labels:
                print(f"  âŒ è¿‡æ»¤æ ¼å¼æ ‡ç­¾: {keyword}")
                continue
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºçº¯è‹±æ–‡ï¼ˆä¸¥æ ¼æ¨¡å¼ï¼‰
            if self._is_pure_english(keyword):
                print(f"  âŒ è¿‡æ»¤çº¯è‹±æ–‡: {keyword}")
                continue
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºçº¯æ•°å­—
            if self._is_pure_number(keyword):
                print(f"  âŒ è¿‡æ»¤çº¯æ•°å­—: {keyword}")
                continue
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºçº¯ç¬¦å·
            if self._is_pure_symbol(keyword):
                print(f"  âŒ è¿‡æ»¤çº¯ç¬¦å·: {keyword}")
                continue
            
            # è‡³å°‘è¦åŒ…å«ä¸€ä¸ªä¸­æ–‡å­—ç¬¦ï¼ˆä¸å¼ºåˆ¶ï¼Œå¦‚æœæ²¡æœ‰å¯èƒ½æ˜¯è‹±æ–‡çŸ­è¯­å’Œä¸­æ–‡æ··åˆï¼‰
            has_chinese = self._has_chinese_char(keyword)
            if not has_chinese:
                # å…è®¸åŒ…å«æ•°å­—å’Œç¬¦å·çš„ç»„åˆï¼Œä½†ä¸¥æ ¼è¿‡æ»¤çº¯è‹±æ–‡
                # ä¾‹å¦‚å…è®¸ "CNNç½‘ç»œ" "2Dæ‰“å°" ä½†ä¸å…è®¸ "CNN" "animation"
                pure_alpha_count = sum(1 for c in keyword if c.isalpha())
                total_count = len(keyword.replace(' ', ''))
                
                # å¦‚æœè¶…è¿‡80%æ˜¯å­—æ¯ï¼Œåˆ™è®¤ä¸ºæ˜¯çº¯è‹±æ–‡ï¼Œè¿‡æ»¤æ‰
                if total_count > 0 and pure_alpha_count > total_count * 0.8:
                    print(f"  âŒ è¿‡æ»¤çº¯è‹±æ–‡è¯ç»„: {keyword}")
                    continue
            
            print(f"  âœ… ä¿ç•™å…³é”®è¯: {keyword}")
            validated.append(keyword)
        
        return validated
    
    @staticmethod
    def _is_pure_english(text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºçº¯è‹±æ–‡"""
        return all(c.isascii() and c.isalpha() for c in text.replace(' ', '').replace('-', '').replace('_', ''))
    
    @staticmethod
    def _is_pure_number(text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºçº¯æ•°å­—"""
        return all(c.isdigit() or c in '.,- ' for c in text)
    
    @staticmethod
    def _is_pure_symbol(text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºçº¯ç¬¦å·"""
        symbols = set('!@#$%^&*()[]{},.;:?/<>\\|~`\'"')
        return all(c in symbols or c.isspace() for c in text)
    
    @staticmethod
    def _has_chinese_char(text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦"""
        for char in text:
            if '\u4e00' <= char <= '\u9fff':  # ä¸­æ–‡å­—ç¬¦èŒƒå›´
                return True
        return False
    
    def extract_keywords_from_clusters(self, knowledge_clusters: List[Dict]) -> List[str]:
        """ä»çŸ¥è¯†èšç±»ä¸­æå–å…³é”®è¯
        
        Args:
            knowledge_clusters: çŸ¥è¯†èšç±»åˆ—è¡¨ï¼ˆé€šå¸¸æ¥è‡ªAIåˆ†æï¼‰
        
        Returns:
            å…³é”®è¯åˆ—è¡¨
        """
        keywords = []
        
        for cluster in knowledge_clusters[:5]:  # æœ€å¤šå–å‰5ä¸ª
            if isinstance(cluster, dict):
                concept = cluster.get("concept", "")
            else:
                concept = str(cluster)
            
            if concept and len(concept) >= 3:
                concept = concept.strip()
                if self._has_chinese_char(concept):
                    keywords.append(concept)
        
        return keywords

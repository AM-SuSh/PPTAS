import os
import tempfile
import json
from typing import Any, Dict, List, Optional, Union

from fastapi import FastAPI, File, UploadFile, HTTPException, Depends, WebSocket
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse

from src.utils.helpers import ensure_supported_ext, save_upload_to_temp, download_to_temp
from src.services.ppt_parser_service import DocumentParserService
from src.services.ppt_expansion_service import PPTExpansionService
from src.services.page_analysis_service import PageDeepAnalysisService
from src.services.ai_tutor_service import AITutorService, ChatMessage
from src.services.reference_search_service import ReferenceSearchService
from src.services.vector_store_service import VectorStoreService
from src.agents.base import LLMConfig
from pydantic import BaseModel, Field

from src.services.mindmap_service import MindmapService

app = FastAPI(title="PPTAS Backend", version="0.2.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

_ai_tutor_service = None
_page_analysis_service = None

def get_ai_tutor():
    """è·å– AI åŠ©æ•™æœåŠ¡å•ä¾‹"""
    global _ai_tutor_service
    if _ai_tutor_service is None:
        config = load_config()
        llm_config = LLMConfig(
            api_key=config["llm"]["api_key"],
            base_url=config["llm"]["base_url"],
            model=config["llm"]["model"]
        )
        _ai_tutor_service = AITutorService(llm_config)
    return _ai_tutor_service

def get_page_analysis():
    """è·å–é¡µé¢åˆ†ææœåŠ¡å•ä¾‹"""
    global _page_analysis_service
    if _page_analysis_service is None:
        config = load_config()
        llm_config = LLMConfig(
            api_key=config["llm"]["api_key"],
            base_url=config["llm"]["base_url"],
            model=config["llm"]["model"]
        )
        _page_analysis_service = PageDeepAnalysisService(llm_config)
    return _page_analysis_service
# ==================== è¯·æ±‚/å“åº”æ¨¡å‹ ====================
class ChatRequest(BaseModel):
    """èŠå¤©è¯·æ±‚"""
    page_id: int
    message: str


class ChatResponse(BaseModel):
    """èŠå¤©å“åº”"""
    page_id: int
    response: str
    timestamp: str


class PageAnalysisRequest(BaseModel):
    """é¡µé¢åˆ†æè¯·æ±‚"""
    page_id: int
    title: str
    content: str
    raw_points: Optional[list] = None
    key_concepts: Optional[list] = None  # å…³é”®æ¦‚å¿µåˆ—è¡¨
    analysis: Optional[str] = None  # æ·±åº¦åˆ†æå†…å®¹


class ReferenceSearchRequest(BaseModel):
    """å‚è€ƒæ–‡çŒ®æœç´¢è¯·æ±‚"""
    query: str
    max_results: int = 10
    search_type: Optional[str] = None  # "academic" | "general" | None


class SemanticSearchRequest(BaseModel):
    """è¯­ä¹‰æœç´¢è¯·æ±‚"""
    query: str
    top_k: int = 5
    file_name: Optional[str] = None
    file_type: Optional[str] = None  # "pdf" æˆ– "pptx"
    min_score: float = 0.0


# ==================== é…ç½®åŠ è½½ ====================
def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = os.path.join(os.path.dirname(__file__), "..", "..", "config.json")
    
    if not os.path.exists(config_path):
        config_path = os.path.join(os.path.dirname(__file__), "..", "config.json")
    
    if os.path.exists(config_path):
        with open(config_path, "r", encoding="utf-8") as f:
            return json.load(f)
    
    # é»˜è®¤é…ç½®
    return {
        "llm": {
            "api_key": os.getenv("api_key", ""),
            "base_url": os.getenv("base_url", "https://api.openai.com/v1"),
            "model": os.getenv("model", "gpt-4")
        },
        "retrieval": {
            "preferred_sources": ["arxiv", "wikipedia"],
            "max_results": 3,
            "local_rag_priority": True
        },
        "expansion": {
            "max_revisions": 2,
            "min_gap_priority": 3,
            "temperature": 0.7
        }
    }


def get_parser_service():
    return DocumentParserService()

def get_mindmap_service():
    return MindmapService()


class MindmapRequest(BaseModel):
    title: str = Field(default="", description="Slide title")
    raw_points: Optional[List[Union[str, Dict[str, Any]]]] = Field(
        default=None,
        description="Slide points; supports plain strings or objects like {text, level}.",
    )
    max_depth: int = Field(default=4, ge=1, le=8)
    max_children_per_node: int = Field(default=20, ge=1, le=100)


class SlidePoint(BaseModel):
    text: str
    level: int = Field(default=0, ge=0)


class SlideItem(BaseModel):
    title: str
    page_num: Optional[int] = None
    raw_points: Optional[List[Union[str, Dict[str, Any], SlidePoint]]] = None


class MindmapFromSlidesRequest(BaseModel):
    title: Optional[str] = Field(default=None, description="æ•´ä½“ PPT æ ‡é¢˜ï¼Œå¯é€‰")
    slides: List[SlideItem]
    max_depth: int = Field(default=4, ge=1, le=8)
    max_children_per_node: int = Field(default=20, ge=1, le=100)


@app.post("/api/v1/mindmap")
async def build_mindmap(
    payload: MindmapRequest,
    svc: MindmapService = Depends(get_mindmap_service),
):
    """
    Build a mindmap tree for the frontend "æ€ç»´å¯¼å›¾" tab.
    Returns: { root: {id,label,children:[...] } }
    """
    return svc.build_mindmap(
        title=payload.title,
        raw_points=payload.raw_points,
        max_depth=payload.max_depth,
        max_children_per_node=payload.max_children_per_node,
    )


@app.post("/api/v1/mindmap/from-slides")
async def build_mindmap_from_slides(
    payload: MindmapFromSlidesRequest,
    svc: MindmapService = Depends(get_mindmap_service),
):
    """
    Build a mindmap for the entire PPT (all slides).
    Expects slides from /api/v1/expand-ppt output.
    """
    return svc.build_mindmap_for_ppt(
        slides=[s.model_dump() for s in payload.slides],
        deck_title=payload.title or "PPT Mindmap",
        max_depth=payload.max_depth,
        max_children_per_node=payload.max_children_per_node,
    )

def get_expansion_service():
    config = load_config()
    llm_config = LLMConfig(
        api_key=config["llm"]["api_key"],
        base_url=config["llm"]["base_url"],
        model=config["llm"]["model"]
    )
    return PPTExpansionService(llm_config)


def get_page_analysis_service():
    config = load_config()
    llm_config = LLMConfig(
        api_key=config["llm"]["api_key"],
        base_url=config["llm"]["base_url"],
        model=config["llm"]["model"]
    )
    return PageDeepAnalysisService(llm_config)


def get_ai_tutor_service():
    config = load_config()
    llm_config = LLMConfig(
        api_key=config["llm"]["api_key"],
        base_url=config["llm"]["base_url"],
        model=config["llm"]["model"]
    )
    return AITutorService(llm_config)


def get_reference_search_service():
    return ReferenceSearchService()


def get_vector_store_service():
    """è·å–å‘é‡å­˜å‚¨æœåŠ¡å®ä¾‹"""
    config = load_config()
    llm_config = LLMConfig(
        api_key=config["llm"]["api_key"],
        base_url=config["llm"]["base_url"],
        model=config["llm"]["model"]
    )
    # ä¼˜å…ˆä½¿ç”¨ vector_store é…ç½®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ knowledge_base è·¯å¾„
    vector_db_path = config.get("vector_store", {}).get("path") or config.get("knowledge_base", {}).get("path", "./ppt_vector_db")
    return VectorStoreService(llm_config, vector_db_path)


# ==================== API ç«¯ç‚¹ ====================

@app.post("/api/v1/expand-ppt")
async def expand_ppt(
    file: Optional[UploadFile] = File(None),
    url: Optional[str] = None,
    parser: DocumentParserService = Depends(get_parser_service),
    vector_store: VectorStoreService = Depends(get_vector_store_service),
):
    """æ¥æ”¶ PPTX/PDF æ–‡ä»¶æˆ– URLï¼Œè¿”å›è§£æåçš„é€»è¾‘ç»“æ„ï¼Œå¹¶å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“ã€‚"""
    if not file and not url:
        raise HTTPException(status_code=400, detail="éœ€è¦ä¸Šä¼ æ–‡ä»¶æˆ–æä¾› url")

    tmp_path = None
    try:
        if url:
            tmp_path, filename = download_to_temp(url)
        else:
            tmp_path, filename = await save_upload_to_temp(file)

        ext = ensure_supported_ext(filename)
        slides = parser.parse_document(tmp_path, ext)
        
        # å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
        try:
            file_type = ext[1:] if ext.startswith('.') else ext  # ç§»é™¤ç‚¹å·
            store_result = vector_store.store_document_slides(
                file_name=filename,
                file_type=file_type,
                slides=slides
            )
            print(f"âœ… å·²å­˜å‚¨ {store_result['total_chunks']} ä¸ªåˆ‡ç‰‡åˆ°å‘é‡æ•°æ®åº“")
        except Exception as e:
            print(f"âš ï¸  å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“å¤±è´¥: {e}")
            # ä¸ä¸­æ–­ä¸»æµç¨‹ï¼Œç»§ç»­è¿”å›è§£æç»“æœ
        
        return {
            "slides": slides,
            "vector_store": {
                "stored": True,
                "total_chunks": store_result.get("total_chunks", 0) if 'store_result' in locals() else 0
            }
        }
    except HTTPException:
        raise
    except Exception as e:
        return JSONResponse(status_code=500, content={"error": str(e)})
    finally:
        if tmp_path and os.path.exists(tmp_path):
            os.remove(tmp_path)


@app.post("/api/v1/analyze-page")
async def analyze_page(
    request: PageAnalysisRequest,
    service: PageDeepAnalysisService = Depends(get_page_analysis_service),
):
    """å¯¹å•ä¸ªé¡µé¢è¿›è¡Œæ·±åº¦åˆ†æ
    
    Args:
        request: åˆ†æè¯·æ±‚
        service: åˆ†ææœåŠ¡
    
    Returns:
        é¡µé¢æ·±åº¦åˆ†æç»“æœ
    """
    try:
        result = service.analyze_page(
            page_id=request.page_id,
            title=request.title,
            content=request.content,
            raw_points=request.raw_points
        )
        
        return {
            "success": True,
            "data": {
                "page_id": result.page_id,
                "title": result.title,
                "raw_content": result.raw_content,
                "deep_analysis": result.deep_analysis,
                "key_concepts": result.key_concepts,
                "learning_objectives": result.learning_objectives,
                "references": result.references,
                "raw_points": result.raw_points
            }
        }
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"error": str(e)}
        )


@app.post("/api/v1/chat")
async def chat(
    request: ChatRequest,
):
    """ä¸ AI åŠ©æ•™å¯¹è¯"""
    try:
        if not request.message or not request.message.strip():
            raise HTTPException(status_code=400, detail="æ¶ˆæ¯ä¸èƒ½ä¸ºç©º")
        
        # è·å–æœåŠ¡å®ä¾‹
        service = get_ai_tutor()
        
        print(f"ğŸ“ èŠå¤©è¯·æ±‚: page_id={request.page_id}, å·²æœ‰ä¸Šä¸‹æ–‡: {list(service.page_context.keys())}")
        
        # æ£€æŸ¥æ˜¯å¦å·²è®¾ç½®ä¸Šä¸‹æ–‡
        if request.page_id not in service.page_context:
            print(f"âš ï¸ é¡µé¢ {request.page_id} æœªåœ¨ä¸Šä¸‹æ–‡ä¸­ï¼Œå½“å‰å·²çŸ¥é¡µé¢: {list(service.page_context.keys())}")
            return {
                "status": "error",
                "response": f"âš ï¸ é¡µé¢å†…å®¹æœªåŠ è½½ã€‚è¯·ç¡®ä¿ï¼š\n1. å·²åˆ‡æ¢åˆ°èŠå¤©æ ‡ç­¾é¡µ\n2. å·²åŠ è½½ PPT å†…å®¹\n3. é¡µé¢å·²å®Œå…¨åˆå§‹åŒ–ï¼ˆpage_id={request.page_id}ï¼‰\n\nå¦‚æœé—®é¢˜æŒç»­å­˜åœ¨ï¼Œè¯·ï¼š\nâ€¢ åˆ·æ–°é¡µé¢\nâ€¢ é‡æ–°ä¸Šä¼  PPT\nâ€¢ æŸ¥çœ‹åç«¯æ—¥å¿—",
                "need_context": True
            }
        
        # è°ƒç”¨åŠ©æ•™æœåŠ¡
        response_text = service.chat(request.page_id, request.message)
        
        from datetime import datetime
        return {
            "status": "ok",
            "response": response_text,
            "page_id": request.page_id,
            "timestamp": datetime.now().isoformat()
        }
    
    except Exception as e:
        print(f"âŒ èŠå¤©å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        
        return {
            "status": "error",
            "response": f"âŒ æŠ±æ­‰,AI æš‚æ—¶æ— æ³•å›ç­”ã€‚é”™è¯¯: {str(e)}",
            "error": str(e)
        }

@app.post("/api/v1/tutor/set-context")
async def set_tutor_context(
    request: PageAnalysisRequest,
):
    """è®¾ç½® AI åŠ©æ•™çš„é¡µé¢ä¸Šä¸‹æ–‡"""
    try:
        # è·å–æœåŠ¡å®ä¾‹
        service = get_ai_tutor()
        
        # ç»„è£…å†…å®¹æ–‡æœ¬
        content_text = request.content
        if not content_text and request.raw_points:
            content_text = "\n".join([
                point.get('text', '') 
                for point in request.raw_points 
                if point.get('type') == 'text'
            ])
        
        # ç¡®ä¿ page_id æ˜¯æ•´æ•°
        page_id = int(request.page_id)
        
        print(f"ğŸ”§ è®¾ç½®ä¸Šä¸‹æ–‡: page_id={page_id}, title={request.title}")
        
        # è®¾ç½®é¡µé¢ä¸Šä¸‹æ–‡
        service.set_page_context(
            page_id=page_id,
            title=request.title,
            content=content_text,
            key_concepts=request.key_concepts or request.raw_points or [],  # ä¼˜å…ˆä½¿ç”¨ key_concepts
            analysis=request.analysis or ""  # ä½¿ç”¨ analysis å­—æ®µ
        )
        
        print(f"âœ… ä¸Šä¸‹æ–‡å·²ä¿å­˜ï¼Œå½“å‰å·²çŸ¥é¡µé¢: {list(service.page_context.keys())}")
        
        # è¿”å›æ¬¢è¿è¯­
        greeting = service.get_assistant_greeting(page_id)
        
        return {
            "status": "ok",
            "page_id": page_id,
            "greeting": greeting,
            "message": "é¡µé¢ä¸Šä¸‹æ–‡å·²è®¾ç½®"
        }
    
    except Exception as e:
        print(f"âŒ è®¾ç½®ä¸Šä¸‹æ–‡å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/tutor/debug/{page_id}")
async def debug_tutor_context(page_id: int):
    """è°ƒè¯•ï¼šæŸ¥çœ‹å½“å‰é¡µé¢ä¸Šä¸‹æ–‡"""
    service = get_ai_tutor()
    context = service.page_context.get(page_id)
    conversation = service.get_conversation_history(page_id)
    
    return {
        "page_id": page_id,
        "has_context": context is not None,
        "context": context,
        "conversation_count": len(conversation),
        "conversation": conversation[-5:] if conversation else []
    }

@app.post("/api/v1/tutor/conversation")
async def get_conversation_history(
    page_id: int,
    service: AITutorService = Depends(get_ai_tutor_service),
):
    """è·å–å¯¹è¯å†å²
    
    Args:
        page_id: é¡µé¢ ID
        service: AI åŠ©æ•™æœåŠ¡
    
    Returns:
        å¯¹è¯å†å²
    """
    try:
        history = service.get_conversation_history(page_id)
        return {
            "page_id": page_id,
            "messages": history
        }
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"error": str(e)}
        )


@app.post("/api/v1/search-references")
async def search_references(
    request: ReferenceSearchRequest,
    service: ReferenceSearchService = Depends(get_reference_search_service),
):
    """æœç´¢å‚è€ƒæ–‡çŒ®
    
    Args:
        request: æœç´¢è¯·æ±‚
        service: æœç´¢æœåŠ¡
    
    Returns:
        æœç´¢ç»“æœ
    """
    try:
        if request.search_type == "academic":
            result = service.search_academic_papers(request.query, request.max_results)
        elif request.search_type == "general":
            result = service.search_general_knowledge(request.query, request.max_results)
        else:
            result = service.search_references(request.query, request.max_results)
        
        return {
            "success": True,
            "query": result.query,
            "total_results": result.total_results,
            "references": [
                {
                    "title": ref.title,
                    "url": ref.url,
                    "source": ref.source,
                    "snippet": ref.snippet
                }
                for ref in result.references
            ]
        }
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"error": str(e)}
        )


@app.post("/api/v1/search-by-concepts")
async def search_by_concepts(
    concepts: list,
    max_per_concept: int = 3,
    service: ReferenceSearchService = Depends(get_reference_search_service),
):
    """æŒ‰æ¦‚å¿µæœç´¢å‚è€ƒæ–‡çŒ®
    
    Args:
        concepts: æ¦‚å¿µåˆ—è¡¨
        max_per_concept: æ¯ä¸ªæ¦‚å¿µçš„æœ€å¤§ç»“æœæ•°
        service: æœç´¢æœåŠ¡
    
    Returns:
        æŒ‰æ¦‚å¿µç»„ç»‡çš„æœç´¢ç»“æœ
    """
    try:
        results = service.search_by_concepts(concepts, max_per_concept)
        
        return {
            "success": True,
            "results": {
                concept: {
                    "query": result.query,
                    "total": result.total_results,
                    "references": [
                        {
                            "title": ref.title,
                            "url": ref.url,
                            "source": ref.source,
                            "snippet": ref.snippet
                        }
                        for ref in result.references
                    ]
                }
                for concept, result in results.items()
            }
        }
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"error": str(e)}
        )


@app.get("/api/v1/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "ok", "version": "0.2.0"}


@app.post("/api/v1/search-semantic")
async def search_semantic(
    request: SemanticSearchRequest,
    vector_store: VectorStoreService = Depends(get_vector_store_service),
):
    """åŸºäºè¯­ä¹‰æœç´¢ PPT/PDF åˆ‡ç‰‡
    
    Args:
        request: æœç´¢è¯·æ±‚
        vector_store: å‘é‡å­˜å‚¨æœåŠ¡
    
    Returns:
        æœç´¢ç»“æœåˆ—è¡¨
    """
    try:
        results = vector_store.search_similar_slides(
            query=request.query,
            top_k=request.top_k,
            file_name=request.file_name,
            file_type=request.file_type,
            min_score=request.min_score
        )
        
        return {
            "success": True,
            "query": request.query,
            "total_results": len(results),
            "results": results
        }
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"error": str(e)}
        )


@app.get("/api/v1/vector-store/stats")
async def get_vector_store_stats(
    vector_store: VectorStoreService = Depends(get_vector_store_service),
):
    """è·å–å‘é‡æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
    
    Args:
        vector_store: å‘é‡å­˜å‚¨æœåŠ¡
    
    Returns:
        ç»Ÿè®¡ä¿¡æ¯
    """
    try:
        stats = vector_store.get_stats()
        return {
            "success": True,
            "stats": stats
        }
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"error": str(e)}
        )


@app.get("/api/v1/vector-store/file/{file_name}")
async def get_file_slides(
    file_name: str,
    vector_store: VectorStoreService = Depends(get_vector_store_service),
):
    """è·å–ç‰¹å®šæ–‡ä»¶çš„æ‰€æœ‰åˆ‡ç‰‡
    
    Args:
        file_name: æ–‡ä»¶å
        vector_store: å‘é‡å­˜å‚¨æœåŠ¡
    
    Returns:
        è¯¥æ–‡ä»¶çš„æ‰€æœ‰åˆ‡ç‰‡
    """
    try:
        results = vector_store.search_by_file(file_name)
        return {
            "success": True,
            "file_name": file_name,
            "total_chunks": len(results),
            "chunks": results
        }
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"error": str(e)}
        )


@app.delete("/api/v1/vector-store/file/{file_name}")
async def delete_file_slides(
    file_name: str,
    vector_store: VectorStoreService = Depends(get_vector_store_service),
):
    """åˆ é™¤ç‰¹å®šæ–‡ä»¶çš„æ‰€æœ‰åˆ‡ç‰‡
    
    Args:
        file_name: æ–‡ä»¶å
        vector_store: å‘é‡å­˜å‚¨æœåŠ¡
    
    Returns:
        åˆ é™¤ç»“æœ
    """
    try:
        success = vector_store.delete_file_slides(file_name)
        return {
            "success": success,
            "file_name": file_name,
            "message": "åˆ é™¤æˆåŠŸ" if success else "æœªæ‰¾åˆ°æ–‡ä»¶æˆ–åˆ é™¤å¤±è´¥"
        }
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"error": str(e)}
        )


@app.get("/api/v1/health/llm")
async def check_llm_connection():
    """æ£€æŸ¥ LLM è¿æ¥çŠ¶æ€ - å¿«é€Ÿè¯Šæ–­"""
    config = load_config()
    llm_config = LLMConfig(
        api_key=config["llm"]["api_key"],
        base_url=config["llm"]["base_url"],
        model=config["llm"]["model"]
    )
    
    # æ£€æŸ¥ API Key é…ç½®
    if not llm_config.api_key:
        return {
            "status": "error",
            "message": "API Key æœªé…ç½®",
            "detail": "è¯·æ£€æŸ¥ config.json ä¸­çš„ llm.api_key å­—æ®µ",
            "configured": False,
            "model": llm_config.model
        }
    
    try:
        # åˆ›å»º LLM å®ä¾‹è¿›è¡Œè¿æ¥æµ‹è¯•
        llm = llm_config.create_llm(temperature=0.5)
        
        # å‘é€ä¸€ä¸ªæå…¶ç®€æ´çš„æµ‹è¯•æ¶ˆæ¯ï¼ˆè¶…å¿«é€Ÿï¼‰
        test_message = "Say OK"
        response = llm.invoke(test_message)
        
        # æ£€æŸ¥æ˜¯å¦å¾—åˆ°æœ‰æ•ˆå“åº”
        if response and response.content:
            return {
                "status": "ok",
                "message": "LLM è¿æ¥æ­£å¸¸",
                "model": llm_config.model,
                "configured": True,
                "response_preview": response.content[:50]
            }
        else:
            return {
                "status": "error",
                "message": "LLM è¿”å›ç©ºç»“æœ",
                "detail": "æœåŠ¡è¿”å›å†…å®¹ä¸ºç©ºï¼Œå¯èƒ½æ˜¯é…ç½®é—®é¢˜",
                "model": llm_config.model,
                "configured": True
            }
    except Exception as e:
        error_msg = str(e).lower()
        
        # æ ¹æ®é”™è¯¯ç±»å‹æä¾›æ›´å…·ä½“çš„è¯Šæ–­
        if "401" in error_msg or "unauthorized" in error_msg or "invalid" in error_msg:
            detail = "API Key æ— æ•ˆæˆ–å·²è¿‡æœŸ - è¯·æ£€æŸ¥ config.json"
        elif "429" in error_msg or "rate_limit" in error_msg or "rate limit" in error_msg:
            detail = "è¶…è¿‡ API è°ƒç”¨é€Ÿç‡é™åˆ¶ï¼Œè¯·ç¨åå†è¯•"
        elif "quota" in error_msg or "exceeded" in error_msg:
            detail = "API é…é¢å·²ç”¨å°½ - è¯·æ£€æŸ¥è´¦æˆ·ä½™é¢"
        elif "timeout" in error_msg or "timed out" in error_msg:
            detail = "è¯·æ±‚è¶…æ—¶ - æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ– LLM æœåŠ¡çŠ¶æ€"
        elif "connection" in error_msg or "refused" in error_msg:
            detail = "æ— æ³•è¿æ¥åˆ° LLM æœåŠ¡ - æ£€æŸ¥ base_url é…ç½®"
        else:
            detail = str(e)
        
        return {
            "status": "error",
            "message": "LLM è¿æ¥å¤±è´¥",
            "detail": detail,
            "model": llm_config.model,
            "configured": True,
            "error_type": type(e).__name__
        }

class SetContextRequest(BaseModel):
    """è®¾ç½®é¡µé¢ä¸Šä¸‹æ–‡è¯·æ±‚"""
    page_id: int
    title: str
    content: str
    raw_points: List[dict] = []
    key_concepts: List[str] = []
    analysis: str = ""


class ChatRequest(BaseModel):
    """èŠå¤©è¯·æ±‚"""
    page_id: int
    message: str


# ===== API ç«¯ç‚¹ =====


@app.get("/api/v1/tutor/conversation")
async def get_conversation_history(page_id: int):
    """è·å–å¯¹è¯å†å²"""
    try:
        history = ai_tutor.get_conversation_history(page_id)
        return {
            "status": "ok",
            "page_id": page_id,
            "history": history,
            "count": len(history)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/api/v1/tutor/conversation/{page_id}")
async def clear_conversation(page_id: int):
    """æ¸…é™¤å¯¹è¯å†å²"""
    try:
        ai_tutor.clear_conversation(page_id)
        return {
            "status": "ok",
            "page_id": page_id,
            "message": "å¯¹è¯å†å²å·²æ¸…é™¤"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8000)


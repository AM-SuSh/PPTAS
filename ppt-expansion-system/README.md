# PPT æ™ºèƒ½æ‰©å±•ç³»ç»Ÿ - é…ç½®ä¸éƒ¨ç½²æŒ‡å—

## ğŸ“‹ ç›®å½•ç»“æ„

```
ppt-expansion-system/
â”œâ”€â”€ ppt_expansion_system.py      # æ ¸å¿ƒç³»ç»Ÿæ¶æ„
â”œâ”€â”€ mcp_tools.py                  # MCP å·¥å…·é›†æˆ
â”œâ”€â”€ streaming_demo.py             # å®Œæ•´ä½¿ç”¨ç¤ºä¾‹
â”œâ”€â”€ config.json                   # é…ç½®æ–‡ä»¶
â”œâ”€â”€ requirements.txt              # ä¾èµ–é¡¹
â”œâ”€â”€ knowledge_sources/            # æœ¬åœ°çŸ¥è¯†åº“æ–‡ä»¶å¤¹
â”‚   â”œâ”€â”€ textbooks/
â”‚   â”œâ”€â”€ papers/
â”‚   â””â”€â”€ notes/
â”œâ”€â”€ knowledge_base/               # å‘é‡æ•°æ®åº“å­˜å‚¨
â””â”€â”€ outputs/                      # è¾“å‡ºæ–‡ä»¶å¤¹
```

## ğŸ”§ ç¯å¢ƒé…ç½®

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

**requirements.txt**:
```
langchain>=0.1.0
langchain-openai>=0.0.5
langchain-community>=0.0.20
langgraph>=0.0.20
chromadb>=0.4.22
pydantic>=2.5.0
python-pptx>=0.6.21
beautifulsoup4>=4.12.0
requests>=2.31.0
PyPDF2>=3.0.0
```

### 2. é…ç½® config.json

```json
{
  "llm": {
    "api_key": "your-api-key-here",
    "base_url": "https://api.openai.com/v1",
    "model": "gpt-4"
  },
  "retrieval": {
    "preferred_sources": ["arxiv", "wikipedia"],
    "max_results": 3,
    "local_rag_priority": true
  },
  "expansion": {
    "max_revisions": 2,
    "min_gap_priority": 3,
    "temperature": 0.7
  },
  "streaming": {
    "enabled": true,
    "chunk_size": 50
  },
  "knowledge_base": {
    "path": "./knowledge_base",
    "chunk_size": 1000,
    "chunk_overlap": 200
  }
}
```

### 3. ç¯å¢ƒå˜é‡è®¾ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼š
```bash
OPENAI_API_KEY=sk-...
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4

# å¯é€‰ï¼šå…¶ä»– LLM æä¾›å•†
# ANTHROPIC_API_KEY=...
# AZURE_OPENAI_ENDPOINT=...
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºç¡€ä½¿ç”¨

```python
from streaming_demo import PPTExpansionPipeline

# åˆå§‹åŒ–
pipeline = PPTExpansionPipeline("config.json")

# å‡†å¤‡ PPT æ–‡æœ¬
ppt_texts = [
    "ç¬¬1é¡µï¼šä¸»é¢˜ä»‹ç»...",
    "ç¬¬2é¡µï¼šæ ¸å¿ƒæ¦‚å¿µ...",
    "ç¬¬3é¡µï¼šåº”ç”¨ç¤ºä¾‹..."
]

# è¿è¡Œ
result = pipeline.run(ppt_texts)

# å¯¼å‡º
pipeline.export_to_markdown(result, "output.md")
```

### ä»æ–‡ä»¶åŠ è½½

```python
# åŠ è½½ PPTX æ–‡ä»¶
ppt_texts = pipeline.load_ppt("lecture.pptx")

# è¿è¡Œæµç¨‹
result = pipeline.run(ppt_texts)
```

### æµå¼å¤„ç†

```python
import asyncio

async def process_streaming():
    pipeline = PPTExpansionPipeline()
    ppt_texts = [...]
    
    async for chunk in pipeline.run_streaming(ppt_texts):
        print(chunk, end="", flush=True)

asyncio.run(process_streaming())
```

## ğŸ“š çŸ¥è¯†åº“ç®¡ç†

### æ·»åŠ æœ¬åœ°æ–‡æ¡£

```python
from streaming_demo import KnowledgeBaseManager

kb_manager = KnowledgeBaseManager()

# ä»æ–‡ä»¶å¤¹æ‰¹é‡æ·»åŠ 
docs = kb_manager.add_documents_from_folder("./knowledge_sources/textbooks")

# æŸ¥çœ‹ç»Ÿè®¡
stats = kb_manager.get_stats()
print(f"æ€»æ–‡æ¡£æ•°: {stats['total_documents']}")
```

### æ”¯æŒçš„æ–‡æ¡£æ ¼å¼

- `.txt` - çº¯æ–‡æœ¬
- `.md` - Markdown
- `.pdf` - PDF æ–‡æ¡£
- `.pptx` - PowerPointï¼ˆéœ€è¦é¢å¤–è§£æï¼‰

## ğŸ” MCP å·¥å…·é…ç½®

### é…ç½®æœç´¢æºä¼˜å…ˆçº§

```python
# åœ¨ config.json ä¸­
{
  "retrieval": {
    "preferred_sources": ["arxiv", "wikipedia", "baike"],
    "source_weights": {
      "arxiv": 1.0,
      "wikipedia": 0.8,
      "baike": 0.6
    }
  }
}
```

### ä½¿ç”¨ç‰¹å®šæœç´¢æº

```python
from mcp_tools import MCPRouter

router = MCPRouter()

# ä»…ä½¿ç”¨å­¦æœ¯æº
results = router.search("transformer attention", preferred_sources=["arxiv"])

# ä»…ä½¿ç”¨ç™¾ç§‘æº
results = router.search("æ·±åº¦å­¦ä¹ ", preferred_sources=["wikipedia", "baike"])
```

## âš™ï¸ é«˜çº§é…ç½®

### è‡ªå®šä¹‰ Agent å‚æ•°

```python
from ppt_expansion_system import LLMConfig, StructureUnderstandingAgent

config = LLMConfig(
    api_key="...",
    base_url="...",
    model="gpt-4"
)

# åˆ›å»ºè‡ªå®šä¹‰ Agent
agent = StructureUnderstandingAgent(config)

# ä¿®æ”¹ temperature
agent.llm.temperature = 0.3
```

### è°ƒæ•´æ ¡éªŒä¸¥æ ¼åº¦

```python
# åœ¨ GraphState ä¸­è®¾ç½®
initial_state = {
    "max_revisions": 3,  # æœ€å¤šä¿®è®¢3æ¬¡
    "check_threshold": 0.8,  # æ ¡éªŒé€šè¿‡é˜ˆå€¼
    ...
}
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### 1. å‘é‡æ•°æ®åº“ä¼˜åŒ–

```python
# å¢åŠ æ£€ç´¢æ•°é‡
retrieval_agent.vectorstore.similarity_search(query, k=5)

# ä½¿ç”¨ MMRï¼ˆæœ€å¤§è¾¹é™…ç›¸å…³æ€§ï¼‰
retrieval_agent.vectorstore.max_marginal_relevance_search(query, k=5)
```

### 2. å¹¶è¡Œå¤„ç†çŸ¥è¯†å•å…ƒ

```python
from concurrent.futures import ThreadPoolExecutor

def process_unit(unit):
    # å¤„ç†å•ä¸ªçŸ¥è¯†å•å…ƒ
    return pipeline.process_knowledge_unit(unit)

with ThreadPoolExecutor(max_workers=4) as executor:
    results = list(executor.map(process_unit, knowledge_units))
```

### 3. æ‰¹é‡ LLM è°ƒç”¨

```python
# ä½¿ç”¨ LangChain çš„æ‰¹å¤„ç†
from langchain.schema.runnable import RunnableLambda

batch_chain = RunnableLambda(lambda x: [
    expansion_agent.run(gap) for gap in x
])

results = batch_chain.batch(knowledge_gaps)
```

## ğŸ› è°ƒè¯•ä¸ç›‘æ§

### å¯ç”¨è¯¦ç»†æ—¥å¿—

```python
import logging

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger("ppt_expansion")

# åœ¨ Agent ä¸­æ·»åŠ æ—¥å¿—
logger.debug(f"å¤„ç†çŸ¥è¯†ç¼ºå£: {gap.concept}")
```

### ä½¿ç”¨ LangSmith è¿½è¸ª

```bash
export LANGCHAIN_TRACING_V2=true
export LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
export LANGCHAIN_API_KEY=your-langsmith-key
export LANGCHAIN_PROJECT=ppt-expansion
```

## ğŸ” å®‰å…¨æ€§å»ºè®®

1. **API Key ç®¡ç†**
   - ä½¿ç”¨ç¯å¢ƒå˜é‡å­˜å‚¨ API Key
   - ä¸è¦å°† config.json æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶

2. **è¾“å…¥éªŒè¯**
   ```python
   def validate_ppt_text(text: str) -> bool:
       # æ£€æŸ¥æ–‡æœ¬é•¿åº¦
       if len(text) > 10000:
           return False
       # æ£€æŸ¥æ•æ„Ÿå†…å®¹
       # ...
       return True
   ```

3. **é€Ÿç‡é™åˆ¶**
   ```python
   from ratelimit import limits, sleep_and_retry
   
   @sleep_and_retry
   @limits(calls=10, period=60)
   def call_llm(prompt):
       # é™åˆ¶æ¯åˆ†é’Ÿ10æ¬¡è°ƒç”¨
       pass
   ```

## ğŸ“– ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1ï¼šå¤„ç†æœºå™¨å­¦ä¹ è¯¾ç¨‹ PPT

```python
# åŠ è½½ PPT
ppt_texts = pipeline.load_ppt("ml_lecture.pptx")

# é…ç½®å€¾å‘å­¦æœ¯æº
config_manager.config["retrieval"]["preferred_sources"] = ["arxiv", "scholar"]

# è¿è¡Œ
result = pipeline.run(ppt_texts)

# æŸ¥çœ‹æ‰©å±•çš„çŸ¥è¯†ç‚¹
for content in result["expanded_content"]:
    print(f"{content.concept} - {content.gap_type}")
    print(content.content)
```

### ç¤ºä¾‹ 2ï¼šæ‰¹é‡å¤„ç†å¤šä¸ª PPT

```python
import glob

ppt_files = glob.glob("lectures/*.pptx")

for ppt_file in ppt_files:
    print(f"å¤„ç†: {ppt_file}")
    ppt_texts = pipeline.load_ppt(ppt_file)
    result = pipeline.run(ppt_texts)
    
    # å¯¼å‡ºåˆ°å¯¹åº”æ–‡ä»¶
    output_name = f"output_{Path(ppt_file).stem}.md"
    pipeline.export_to_markdown(result, output_name)
```

### ç¤ºä¾‹ 3ï¼šé›†æˆåˆ° Web åº”ç”¨

```python
from flask import Flask, request, jsonify

app = Flask(__name__)
pipeline = PPTExpansionPipeline()

@app.route('/expand', methods=['POST'])
def expand_ppt():
    data = request.json
    ppt_texts = data.get('ppt_texts', [])
    
    result = pipeline.run(ppt_texts)
    
    return jsonify({
        'success': True,
        'ppt_id': result['ppt_id'],
        'final_notes': result['final_notes'],
        'stats': result['stats']
    })

@app.route('/stream-expand', methods=['POST'])
async def stream_expand():
    # æµå¼å“åº”
    async def generate():
        async for chunk in pipeline.run_streaming(ppt_texts):
            yield f"data: {chunk}\n\n"
    
    return Response(generate(), mimetype='text/event-stream')
```

## ğŸ§ª æµ‹è¯•

### å•å…ƒæµ‹è¯•ç¤ºä¾‹

```python
import unittest

class TestPPTExpansion(unittest.TestCase):
    def setUp(self):
        self.pipeline = PPTExpansionPipeline("test_config.json")
    
    def test_structure_understanding(self):
        ppt_text = "Self-Attention: Q, K, V matrices"
        # æµ‹è¯•ç»“æ„ç†è§£
        # ...
    
    def test_gap_identification(self):
        # æµ‹è¯•ç¼ºå£è¯†åˆ«
        # ...

if __name__ == '__main__':
    unittest.main()
```

## ğŸ“ æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜

1. **å‘é‡æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥**
   - æ£€æŸ¥ chromadb ç‰ˆæœ¬å…¼å®¹æ€§
   - ç¡®ä¿ knowledge_base ç›®å½•æœ‰å†™æƒé™

2. **MCP å·¥å…·æœç´¢å¤±è´¥**
   - æ£€æŸ¥ç½‘ç»œè¿æ¥
   - éªŒè¯ API é…é¢

3. **LLM è°ƒç”¨è¶…æ—¶**
   - å¢åŠ  max_retries
   - è°ƒæ•´ timeout å‚æ•°

## ğŸ“ æ›´æ–°æ—¥å¿—

- **v1.0.0** - åˆå§‹ç‰ˆæœ¬
  - å®Œæ•´çš„ 6-step Agent æµç¨‹
  - æ”¯æŒæœ¬åœ° RAG å’Œ MCP å·¥å…·
  - æµå¼è¾“å‡ºæ”¯æŒ

---

**æ›´å¤šä¿¡æ¯**: æŸ¥çœ‹é¡¹ç›® README.md å’Œä»£ç æ³¨é‡Š